# ğŸš— Vehicle Data Pipeline Project ğŸš€

## ğŸ“Œ Overview
This project is a complete **MLOps pipeline** that involves **data ingestion, validation, transformation, model training, and deployment** using **MongoDB, AWS, Docker, and CI/CD** integration with GitHub Actions. It enables **real-time vehicle data processing** and prediction.

## ğŸ¯ Features
âœ… **Automated Data Pipeline** - Ingest, validate, and transform vehicle data from MongoDB Atlas.  
âœ… **Machine Learning Model Training** - Train models for vehicle data analysis and prediction.  
âœ… **Cloud Storage & Deployment** - AWS S3 for model storage, EC2 for deployment.  
âœ… **CI/CD Pipeline** - Automated deployment via GitHub Actions and AWS services.  
âœ… **Dockerized App** - Containerized for smooth deployment and scaling.  
âœ… **Logging & Exception Handling** - Robust logging and error handling for debugging.  

---

## ğŸ— Project Setup

### ğŸ”¹ Step 1: Create & Activate Virtual Environment
```bash
conda create -n vehicle python=3.10 -y
conda activate vehicle
```

### ğŸ”¹ Step 2: Install Dependencies
```bash
pip install -r requirements.txt
```

### ğŸ”¹ Step 3: Setup MongoDB Atlas ğŸ“¦
1ï¸âƒ£ Sign up at [MongoDB Atlas](https://www.mongodb.com/atlas) & create a new project.  
2ï¸âƒ£ Create a cluster â†’ Select **M0 Free Tier** â†’ Deploy.  
3ï¸âƒ£ Create a **DB user** with username & password.  
4ï¸âƒ£ Set **Network Access** to `0.0.0.0/0` (accessible from anywhere).  
5ï¸âƒ£ Get the **Connection String** (`mongodb+srv://<username>:<password>@cluster.mongodb.net/`).  

### ğŸ”¹ Step 4: Push Data to MongoDB
- Store dataset in the `notebook` folder and load it into **MongoDB Atlas** using `mongoDB_demo.ipynb`.  
- Verify data in **MongoDB Atlas â†’ Browse Collections**.

### ğŸ”¹ Step 5: Implement Logging & Exception Handling ğŸ“
- Develop logging in `logger.py` & exception handling in `exception.py`.  
- Test with `demo.py`.

### ğŸ”¹ Step 6: Data Ingestion ğŸ“¥
1ï¸âƒ£ Define constants in `constants/__init__.py`.  
2ï¸âƒ£ Set up **MongoDB connection** in `configuration/mongo_db_connections.py`.  
3ï¸âƒ£ Implement ingestion logic in `data_access/proj1_data.py`.  
4ï¸âƒ£ Define ingestion config in `entity/config_entity.py`.  
5ï¸âƒ£ Run `demo.py` to test data ingestion.

### ğŸ”¹ Step 7: Setup AWS â˜ï¸
1ï¸âƒ£ Login to AWS Console â†’ Go to **IAM** â†’ Create user (`firstproj`).  
2ï¸âƒ£ Attach **AdministratorAccess** policy.  
3ï¸âƒ£ Generate & download **AWS access keys**.  
4ï¸âƒ£ Set environment variables:
```bash
export AWS_ACCESS_KEY_ID="your_key"
export AWS_SECRET_ACCESS_KEY="your_secret_key"
export AWS_DEFAULT_REGION="us-east-1"
```
5ï¸âƒ£ Configure **AWS S3 Bucket** (`my-model-mlopsproj`).

### ğŸ”¹ Step 8: Model Training & Evaluation ğŸ“Š
- Implement `Data Validation`, `Data Transformation`, and `Model Trainer` components.  
- Store trained models in **AWS S3** using `aws_storage/s3_estimator.py`.  

### ğŸ”¹ Step 9: Deploy Model with CI/CD ğŸš€
1ï¸âƒ£ **Docker Setup:**  
   - Create `Dockerfile` & `.dockerignore`.  
   - Build & test Docker container locally.
2ï¸âƒ£ **GitHub Actions:**  
   - Create `.github/workflows/aws.yaml` for automation.
3ï¸âƒ£ **AWS EC2 Setup:**  
   - Create **EC2 Instance** (`vehicledata-machine`).  
   - Install Docker on EC2:
   ```bash
   curl -fsSL https://get.docker.com -o get-docker.sh
   sudo sh get-docker.sh
   ```
4ï¸âƒ£ **Self-Hosted Runner:**  
   - Connect **EC2 to GitHub Actions** for CI/CD.
5ï¸âƒ£ **Expose Port for Deployment:**  
   - Open port `5000` in **AWS Security Group**.
6ï¸âƒ£ **Launch the App:**  
   - Access via `http://<public-ip>:5000` in your browser.

---

## ğŸ¤ Contributing
Contributions are welcome! Feel free to submit a pull request.  
